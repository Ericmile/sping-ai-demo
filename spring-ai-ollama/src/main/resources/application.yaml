server:
  port: 8080

spring:
  ai:
    ollama:
      baseUrl: http://localhost:11434
      chat:
        options:
          model: deepseek-r1:7b
          temperature: 0.7  
      embedding:
        model: quentinz/bge-large-zh-v1.5:latest
    vectorstore:
      chroma:
        initialize-schema: true
        collection-name: demo_cllection
        client:
          host: http://localhost
          port: 8000